{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_data = pd.read_csv('/Users/skylerwilson/Desktop/Lighthouse_Labs/Projects/final_project/data/Project_Data/parts_data_functions.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sales data function\n",
    "def clean_sales_data(df, column_names):\n",
    "    for col in column_names:  \n",
    "        df[col] = np.abs(df[col])\n",
    "    return df\n",
    "\n",
    "# Clean quantity data function\n",
    "def clean_quantity_data(df, quantity_col):\n",
    "    return df[df[quantity_col] > 0]\n",
    "\n",
    "# Clean turnover data function\n",
    "def clean_turnover_data(df, turnover_col):\n",
    "    return df[df[turnover_col] >= 0]\n",
    "\n",
    "def z_score(column, threshold=2):\n",
    "    z_scores = (column - column.mean()) / column.std()\n",
    "    return np.abs(z_scores) < threshold\n",
    "\n",
    "sales_data = ['Sales Last Month', 'Sales Last 3 Months', 'Sales Last 6 Months', 'Sales Last 9 Months',\n",
    "              'Sales Last 12 Months', 'Sales Last 2 Years', 'Sales Last 3 Years',\n",
    "              'Sales Last 4 Years', 'Sales Last 5 Years', 'Sales Last 10 Years',\n",
    "              'Months No Sale', 'Reorder Point', 'Sales - Jan', 'Sales - Feb',\n",
    "              'Sales - Mar', 'Sales - Apr', 'Sales - May', 'Sales - Jun',\n",
    "              'Sales - Jul', 'Sales - Aug', 'Sales - Sep', 'Sales - Oct',\n",
    "              'Sales - Nov', 'Sales - Dec', 'Sales - 1st Qtr', 'Sales - 2nd Qtr',\n",
    "              'Sales - 3rd Qtr', 'Sales - 4th Qtr', 'Sales - This Year','Sales - Last Year']\n",
    "quantity_col = 'Quantity'\n",
    "turnover_col = 'Turnover'\n",
    "num_cols = parts_data.select_dtypes(include='number').columns\n",
    "\n",
    "# Apply preprocessing steps\n",
    "parts_data = clean_sales_data(parts_data, sales_data)\n",
    "parts_data = clean_quantity_data(parts_data, quantity_col)\n",
    "parts_data = clean_turnover_data(parts_data, turnover_col)\n",
    "\n",
    "\n",
    "# Apply z-score transformation to numerical columns\n",
    "parts_data[num_cols] = parts_data[parts_data[num_cols].apply(z_score)][num_cols]\n",
    "\n",
    "#deals with columns that dont have data yet so they end up as NaN when they shouldnt\n",
    "parts_data[num_cols] = np.where(parts_data[num_cols].isna(), 0, parts_data[num_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = parts_data.select_dtypes(include='number')\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Randomized SVD Transformer\n",
    "class RandomizedSVDTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        U, sigma, VT = randomized_svd(X, n_components=self.n_components)\n",
    "        self.U = U\n",
    "        self.sigma = sigma\n",
    "        self.VT = VT\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        transformed_data = X.dot(self.VT.T)\n",
    "        return transformed_data\n",
    "\n",
    "svd_components = 5\n",
    "k = 10\n",
    "\n",
    "# Create FeatureUnion combining SVD and SelectKBest\n",
    "features = FeatureUnion([\n",
    "    ('svd', RandomizedSVDTransformer(n_components=svd_components)),\n",
    "    ('select_k_best', SelectKBest(score_func=f_regression, k=k))\n",
    "])\n",
    "\n",
    "# Create your pipeline using the defined features FeatureUnion\n",
    "pipeline = Pipeline([\n",
    "    ('features', features),\n",
    "    ('scaler', RobustScaler())\n",
    "    #('model', YourModelHere())  # Replace with the appropriate model\n",
    "])\n",
    "\n",
    "# Fit and transform on training data\n",
    "#X_train_scaled = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Transform on testing data\n",
    "#X_test_scaled = pipeline.transform(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
