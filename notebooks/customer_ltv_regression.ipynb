{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from scipy.stats import yeojohnson\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from xgboost import XGBRegressor\n",
    "from shap import Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_data = pd.read_csv('/Users/skylerwilson/Desktop/Lighthouse_Labs/Projects/final_project/data/Project_Data/final_parts_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sales data function\n",
    "def clean_sales_data(df, column_names):\n",
    "    for col in column_names:  \n",
    "        df[col] = np.abs(df[col])\n",
    "    return df\n",
    "\n",
    "# Clean quantity data function\n",
    "def clean_quantity_data(df, quantity_col):\n",
    "    return df[df[quantity_col] > 0]\n",
    "\n",
    "# Clean turnover data function\n",
    "def clean_negative_data(df, turnover_col):\n",
    "    return df[df[turnover_col] >= 0]\n",
    "\n",
    "\n",
    "def z_score(column, threshold=2):\n",
    "    z_scores = (column - column.mean()) / column.std()\n",
    "    return np.abs(z_scores) < threshold\n",
    "\n",
    "sales_data = ['Sales Last Month', 'Sales Last 3 Months', 'Sales Last 6 Months', 'Sales Last 9 Months',\n",
    "              'Sales Last 12 Months', 'Sales Last 2 Years', 'Sales Last 3 Years',\n",
    "              'Sales Last 4 Years', 'Sales Last 5 Years', 'Sales Last 10 Years',\n",
    "              'Months No Sale', 'Reorder Point', 'Sales - Jan', 'Sales - Feb',\n",
    "              'Sales - Mar', 'Sales - Apr', 'Sales - May', 'Sales - Jun',\n",
    "              'Sales - Jul', 'Sales - Aug', 'Sales - Sep', 'Sales - Oct',\n",
    "              'Sales - Nov', 'Sales - Dec', 'Sales - 1st Qtr', 'Sales - 2nd Qtr',\n",
    "              'Sales - 3rd Qtr', 'Sales - 4th Qtr', 'Sales - This Year','Sales - Last Year']\n",
    "quantity_col = 'Quantity'\n",
    "turnover_col = 'Turnover'\n",
    "\n",
    "num_cols = parts_data.select_dtypes(include='number').columns\n",
    "\n",
    "# Apply preprocessing steps\n",
    "parts_data = clean_sales_data(parts_data, sales_data)\n",
    "parts_data = clean_quantity_data(parts_data, quantity_col)\n",
    "parts_data = clean_negative_data(parts_data, turnover_col)\n",
    "\n",
    "\n",
    "# Apply z-score transformation to numerical columns\n",
    "parts_data[num_cols] = parts_data[parts_data[num_cols].apply(z_score)][num_cols]\n",
    "\n",
    "#deals with columns that dont have data yet so they end up as NaN when they shouldnt\n",
    "parts_data[num_cols] = np.where(parts_data[num_cols].isna(), 0, parts_data[num_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer classes\n",
    "class YeoJohnsonTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        transformed_data = X.copy()\n",
    "        for col in self.columns:\n",
    "            transformed_data[col], _ = yeojohnson(X[col] + 0.01)  # Adding 0.01 to avoid zero values\n",
    "        return transformed_data\n",
    "\n",
    "# Load and preprocess the data\n",
    "y = parts_data['Customer LTV']\n",
    "X = parts_data.select_dtypes(include='number').drop(columns=['Customer LTV'])\n",
    "constant_columns = X.columns[X.nunique() == 1]\n",
    "X.drop(columns=constant_columns, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Define columns to transform\n",
    "cols_to_transform = X.columns\n",
    "\n",
    "# Column transformer for Yeo-Johnson transformation\n",
    "yeo_johnson_cols = ColumnTransformer(\n",
    "    transformers=[('yeo_johnson', YeoJohnsonTransformer(columns=cols_to_transform), cols_to_transform)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create FeatureUnion combining TruncatedSVD and SelectKBest\n",
    "features = FeatureUnion([\n",
    "    ('svd', TruncatedSVD(n_components=5)),\n",
    "    ('select_k_best', SelectKBest(score_func=f_regression, k=10))\n",
    "])\n",
    "\n",
    "# Create the final pipeline with the best hyperparameters\n",
    "final_pipeline = Pipeline([\n",
    "    ('transformer', yeo_johnson_cols),\n",
    "    ('features', features),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('regressor', XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.8,\n",
    "        gamma=0,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=10,\n",
    "        objective='reg:squarederror'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the final pipeline on the training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Transform the testing data using the pipeline\n",
    "X_test_transformed = final_pipeline.named_steps['transformer'].transform(X_test)\n",
    "X_test_transformed = final_pipeline.named_steps['features'].transform(X_test_transformed)\n",
    "X_test_transformed = final_pipeline.named_steps['scaler'].transform(X_test_transformed)\n",
    "\n",
    "# Predict on the transformed test data\n",
    "y_pred = final_pipeline.named_steps['regressor'].predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 24875.01096900962\n",
      "Root Mean Squared Error: 157.71813772996947\n",
      "Mean Absolute Error: 47.0056216804713\n",
      "R squared Value: 0.9892056861966302\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Evaluate your model using appropriate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f'R squared Value: {r_squared}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
